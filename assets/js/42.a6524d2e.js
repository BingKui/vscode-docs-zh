(window.webpackJsonp=window.webpackJsonp||[]).push([[42],{220:function(t,a,e){"use strict";e.r(a);var s=e(0),n=Object(s.a)({},(function(){var t=this,a=t.$createElement,e=t._self._c||a;return e("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[e("h1",{attrs:{id:"syntax-highlight-guide"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#syntax-highlight-guide","aria-hidden":"true"}},[t._v("#")]),t._v(" Syntax Highlight Guide")]),t._v(" "),e("p",[t._v("Syntax highlighting determines the color and style of source code displayed in the Visual Studio Code editor. It is responsible for colorizing keywords like "),e("code",[t._v("if")]),t._v(" or "),e("code",[t._v("for")]),t._v(" in JavaScript differently than strings and comments and variable names.")]),t._v(" "),e("p",[t._v("There are two components to syntax highlighting:")]),t._v(" "),e("ul",[e("li",[t._v("Breaking text into a list of tokens and scopes using a grammar")]),t._v(" "),e("li",[t._v("Then using a theme to map these scopes to specific colors and styles")])]),t._v(" "),e("p",[t._v("This document only discusses the first part: breaking text into tokens and scopes that existing color themes can colorize. For more information about customizing the styling of different scopes in the editor, see the "),e("a",{attrs:{href:"/api/extension-guides/color-theme#syntax-colors"}},[t._v("Color Theme Guide")])]),t._v(" "),e("h2",{attrs:{id:"textmate-grammars"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#textmate-grammars","aria-hidden":"true"}},[t._v("#")]),t._v(" TextMate grammars")]),t._v(" "),e("p",[t._v("VS Code uses "),e("a",{attrs:{href:"https://macromates.com/manual/en/language_grammars",target:"_blank",rel:"noopener noreferrer"}},[t._v("TextMate grammars"),e("OutboundLink")],1),t._v(" to break text into a list of tokens. TextMate grammars are a structured collection of "),e("a",{attrs:{href:"https://macromates.com/manual/en/regular_expressions",target:"_blank",rel:"noopener noreferrer"}},[t._v("Oniguruma regular expressions"),e("OutboundLink")],1),t._v(" and are typically written as a plist or JSON. You can find a good introduction to TextMate grammars "),e("a",{attrs:{href:"https://www.apeth.com/nonblog/stories/textmatebundle.html",target:"_blank",rel:"noopener noreferrer"}},[t._v("here"),e("OutboundLink")],1),t._v(", and you can take a look at existing TextMate grammars to learn more about how they work.")]),t._v(" "),e("h3",{attrs:{id:"tokens-and-scopes"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#tokens-and-scopes","aria-hidden":"true"}},[t._v("#")]),t._v(" Tokens and scopes")]),t._v(" "),e("p",[t._v("Tokens are one or more characters that are part of the same program element. Example tokens include operators such as "),e("code",[t._v("+")]),t._v(" and "),e("code",[t._v("*")]),t._v(", variable names such as "),e("code",[t._v("myVar")]),t._v(", or strings such as "),e("code",[t._v('"my string"')]),t._v(".")]),t._v(" "),e("p",[t._v("Each token is associated with a scope that defines the context of the token. A scope is a dot separated list of identifiers that specify the context of the current token. The "),e("code",[t._v("+")]),t._v(" operation in JavaScript for example has the scope "),e("code",[t._v("keyword.operator.arithmetic.js")]),t._v(".")]),t._v(" "),e("p",[t._v("Themes map scopes to colors and styles to provide syntax highlighting. TextMate provides "),e("a",{attrs:{href:"https://macromates.com/manual/en/language_grammars",target:"_blank",rel:"noopener noreferrer"}},[t._v("list of common scopes"),e("OutboundLink")],1),t._v(" that many themes target. In order to have your grammar as broadly supported as possible, try to build on existing scopes rather than defining new ones.")]),t._v(" "),e("p",[t._v("Scopes nest so that each token is also associated with a list of parent scopes. The example below uses the "),e("a",{attrs:{href:"#scope-inspector"}},[t._v("scope inspector")]),t._v(" to show the scope hierarchy for the "),e("code",[t._v("+")]),t._v(" operator in a simple JavaScript function. The most specific scope is listed at the top, with more general parent scopes listed below:")]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/scopes.png",alt:"syntax highlighting scopes"}})]),t._v(" "),e("p",[t._v("Parent scope information is also used for theming. When a theme targets a scope, all tokens with that parent scope will be colorized unless the theme also provides a more specific colorization for their individual scopes.")]),t._v(" "),e("h3",{attrs:{id:"contributing-a-basic-grammar"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#contributing-a-basic-grammar","aria-hidden":"true"}},[t._v("#")]),t._v(" Contributing a basic grammar")]),t._v(" "),e("p",[t._v("VS Code supports json TextMate grammars. These are contributed through the "),e("code",[t._v("grammars")]),t._v(" "),e("a",{attrs:{href:"/api/references/contribution-points"}},[t._v("contribution point")]),t._v(".")]),t._v(" "),e("p",[t._v("Each grammar contribution specifies: the identifier of the language the grammar applies to, the top level scope name for the tokens of the grammar, and the relative path to a grammar file. The example below shows a grammar contribution for a fictional "),e("code",[t._v("abc")]),t._v(" language:")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contributes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"languages"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"id"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"extensions"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('".abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"grammars"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"language"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"path"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./syntaxes/abc.tmGrammar.json"')]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("The grammar file itself consists of a top level rule. This is typically split into a "),e("code",[t._v("patterns")]),t._v(" section that lists the top level elements of the program and a "),e("code",[t._v("repository")]),t._v(" that defines each of the elements. Other rules in the grammar can reference elements from the "),e("code",[t._v("repository")]),t._v(" using "),e("code",[t._v('{ "include": "#id" }')]),t._v(".")]),t._v(" "),e("p",[t._v("The example "),e("code",[t._v("abc")]),t._v(" grammar marks the letters "),e("code",[t._v("a")]),t._v(", "),e("code",[t._v("b")]),t._v(", and "),e("code",[t._v("c")]),t._v(" as keywords, and nestings of parens as expressions.")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"patterns"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"include"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"#expression"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"repository"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"expression"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"patterns"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"include"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"#letter"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"include"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"#paren-expression"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"letter"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"match"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"a|b|c"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"keyword.letter"')]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"paren-expression"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"begin"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\("')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"end"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"\\\\)"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"beginCaptures"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"0"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"punctuation.paren.open"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"endCaptures"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"0"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"punctuation.paren.close"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"expression.group"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"patterns"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"include"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"#expression"')]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("The grammar engine will try to successively apply the "),e("code",[t._v("expression")]),t._v(" rule to all text in the document. For a simple program such as:")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("a\n(\n    b\n)\nx\n(\n    (\n        c\n        xyz\n    )\n)\n(\na\n")])])]),e("p",[t._v("The example grammar produces the following scopes (listed left-to-right from most specific to least specific scope):")]),t._v(" "),e("div",{staticClass:"language- extra-class"},[e("pre",{pre:!0,attrs:{class:"language-text"}},[e("code",[t._v("a               keyword.letter, source.abc\n(               punctuation.paren.open, expression.group, source.abc\n    b           keyword.letter, expression.group, source.abc\n)               punctuation.paren.close, expression.group, source.abc\nx               source.abc\n(               punctuation.paren.open, expression.group, source.abc\n    (           punctuation.paren.open, expression.group, expression.group, source.abc\n        c       keyword.letter, expression.group, expression.group, source.abc\n        xyz     expression.group, expression.group, source.abc\n    )           punctuation.paren.close, expression.group, expression.group, source.abc\n)               punctuation.paren.close, expression.group, source.abc\n(               source.abc\na               keyword.letter, source.abc\n")])])]),e("p",[t._v("Note that text that is not matched by one of the rules, such as the string "),e("code",[t._v("xyz")]),t._v(", is included in the current scope. The last paren at the end of the file is not part of the an "),e("code",[t._v("expression.group")]),t._v(" since the "),e("code",[t._v("end")]),t._v(" rule is not matched.")]),t._v(" "),e("h3",{attrs:{id:"embedded-languages"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#embedded-languages","aria-hidden":"true"}},[t._v("#")]),t._v(" Embedded languages")]),t._v(" "),e("p",[t._v("If your grammar include embedded languages within the parent language, such as CSS style blocks in HTML, you can use the "),e("code",[t._v("embeddedLanguages")]),t._v(" contribution point to tell VS Code to treat the embedded language as distinct from the parent language. This ensures that bracket matching, commenting, and other basic language features work as expected in the embedded language.")]),t._v(" "),e("p",[t._v("The "),e("code",[t._v("embeddedLanguages")]),t._v(" contribution point maps a scope in the embedded language to a top level language scope. In the example below, any tokens in the "),e("code",[t._v("meta.embedded.block.javascript")]),t._v(" scope will be treated as javascript content:")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contributes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"grammars"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"path"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./syntaxes/abc.tmLanguage.json"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.abc"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"embeddedLanguages"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"meta.embedded.block.javascript"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"javascript"')]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("Now if you try to comment code or trigger snippets inside an set of tokens marked "),e("code",[t._v("meta.embedded.block.javascript")]),t._v(", they will get the correct "),e("code",[t._v("//")]),t._v(" JavaScript style comment and the correct JavaScript snippets.")]),t._v(" "),e("h2",{attrs:{id:"developing-a-new-grammar-extension"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#developing-a-new-grammar-extension","aria-hidden":"true"}},[t._v("#")]),t._v(" Developing a new grammar extension")]),t._v(" "),e("p",[t._v("To quickly create a new grammar extension, use "),e("a",{attrs:{href:"/api/get-started/your-first-extension"}},[t._v("VS Code's Yeoman templates")]),t._v(" to run "),e("code",[t._v("yo code")]),t._v(" and select the "),e("code",[t._v("New Language")]),t._v(" option:")]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/yo-new-language.png",alt:"Selecting the 'new language' template in 'yo code'"}})]),t._v(" "),e("p",[t._v("Yeoman will walk you through some basic questions to scaffold the new extension. The important questions for creating a new grammar are:")]),t._v(" "),e("ul",[e("li",[e("code",[t._v("Language Id")]),t._v(" - A unique identifier for your language.")]),t._v(" "),e("li",[e("code",[t._v("Language Name")]),t._v(" - A human readable name for your language.")]),t._v(" "),e("li",[e("code",[t._v("Scope names")]),t._v(" - Root TextMate scope name for your grammar")])]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/yo-new-language-questions.png",alt:"Filling in the 'new language' questions"}})]),t._v(" "),e("p",[t._v("The generator assumes that you want to define both a new language and a new grammar for that language. If you are creating a grammar for an existing language, just fill these in with your target language's information and be sure to delete the "),e("code",[t._v("languages")]),t._v(" contribution point in the generated "),e("code",[t._v("package.json")]),t._v(".")]),t._v(" "),e("p",[t._v("After answering all the questions, Yeoman will create a new extension with the structure:")]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/generated-new-language-extension.png",alt:"A new language extension"}})]),t._v(" "),e("p",[t._v("Remember, if you are contributing a grammar to a language that VS Code already knows about, be sure to delete the "),e("code",[t._v("languages")]),t._v(" contribution point in the generated "),e("code",[t._v("package.json")]),t._v(".")]),t._v(" "),e("h3",{attrs:{id:"converting-an-existing-textmate-grammar"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#converting-an-existing-textmate-grammar","aria-hidden":"true"}},[t._v("#")]),t._v(" Converting an existing TextMate grammar")]),t._v(" "),e("p",[e("code",[t._v("yo code")]),t._v(" can also help convert an existing TextMate grammar to a VS Code extension. Again, start by running "),e("code",[t._v("yo code")]),t._v(" and selecting "),e("code",[t._v("Language extension")]),t._v(". When asked for an existing grammar file, give it the full path to either a "),e("code",[t._v(".tmLanguage")]),t._v(" or "),e("code",[t._v(".json")]),t._v(" TextMate grammar file:")]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/yo-convert.png",alt:"Converting an existing TextMate grammar"}})]),t._v(" "),e("h3",{attrs:{id:"using-yaml-to-write-a-grammar"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#using-yaml-to-write-a-grammar","aria-hidden":"true"}},[t._v("#")]),t._v(" Using YAML to write a grammar")]),t._v(" "),e("p",[t._v("As a grammar grows more complex, it can become difficult to understand and maintain it as json. If you find yourself writing complex regular expressions or needing to add comments to explain aspects of the grammar, consider using yaml to define your grammar instead.")]),t._v(" "),e("p",[t._v("Yaml grammars have the exact same structure as a json based grammar but allow you to use yaml's more concise syntax, along with features such as multi-line strings and comments.")]),t._v(" "),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/yaml-grammar.png",alt:"A yaml grammar using multiline strings and comments"}})]),t._v(" "),e("p",[t._v("VS Code can only load json grammars, so yaml based grammars must be converted to json. The "),e("a",{attrs:{href:"https://www.npmjs.com/package/js-yaml",target:"_blank",rel:"noopener noreferrer"}},[e("code",[t._v("js-yaml")]),t._v(" package"),e("OutboundLink")],1),t._v(" and command-line tool makes this easy.")]),t._v(" "),e("div",{staticClass:"language-bash extra-class"},[e("pre",{pre:!0,attrs:{class:"language-bash"}},[e("code",[e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Install js-yaml as a development only dependency in your extension")]),t._v("\n$ "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("npm")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token function"}},[t._v("install")]),t._v(" js-yaml --save-dev\n\n"),e("span",{pre:!0,attrs:{class:"token comment"}},[t._v("# Use the command-line tool to convert the yaml grammar to json")]),t._v("\n$ npx js-yaml syntaxes/abc.tmLanguage.yaml "),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(">")]),t._v(" syntaxes/abc.tmLanguage.json\n")])])]),e("h3",{attrs:{id:"scope-inspector"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#scope-inspector","aria-hidden":"true"}},[t._v("#")]),t._v(" Scope inspector")]),t._v(" "),e("p",[t._v("VS Code's built-in scope inspector tool helps debug grammars. It displays the scopes for the token at the current position in a file, along with metadata about which theme rules apply to that token.")]),t._v(" "),e("p",[t._v("Trigger the scope inspector from the Command Palette with the "),e("code",[t._v("Developer: Inspect TM Scopes")]),t._v(" command or "),e("a",{attrs:{href:"/docs/getstarted/keybindings"}},[t._v("create a keybinding")]),t._v(" for it:")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"key"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"cmd+alt+shift+i"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"command"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"editor.action.inspectTMScopes"')]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[e("img",{attrs:{src:"images/syntax-highlighting/scope-inspector.png",alt:"scope inspector"}})]),t._v(" "),e("p",[t._v("The scope inspector displays the following information:")]),t._v(" "),e("ol",[e("li",[t._v("The current token.")]),t._v(" "),e("li",[t._v("Metadata about the token and information about its computed appearance. If you are working with embedded languages, the important entries here "),e("code",[t._v("language")]),t._v(" and "),e("code",[t._v("token type")]),t._v(".")]),t._v(" "),e("li",[t._v("Theme rules that apply to the token. This only shows the theme rules that are responsible for the token's current style, it does not show overridden rules.")]),t._v(" "),e("li",[t._v("Complete scope list, with the most specific scope at the top.")])]),t._v(" "),e("h2",{attrs:{id:"injection-grammars"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#injection-grammars","aria-hidden":"true"}},[t._v("#")]),t._v(" Injection grammars")]),t._v(" "),e("p",[t._v("Injection grammars let you extend an existing grammar. An injection grammar is a regular TextMate grammar that is injected into a specific scope within an existing grammar. Example applications of injection grammars:")]),t._v(" "),e("ul",[e("li",[t._v("Highlighting keywords such as "),e("code",[t._v("TODO")]),t._v(" in comments.")]),t._v(" "),e("li",[t._v("Add more specific scope information to an existing grammar.")]),t._v(" "),e("li",[t._v("Adding highlighting for a new language to Markdown fenced code blocks.")])]),t._v(" "),e("h3",{attrs:{id:"creating-a-basic-injection-grammar"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#creating-a-basic-injection-grammar","aria-hidden":"true"}},[t._v("#")]),t._v(" Creating a basic injection grammar")]),t._v(" "),e("p",[t._v("Injection grammars are contributed though the "),e("code",[t._v("package.json")]),t._v(" just like regular grammars. However, instead of specifying a "),e("code",[t._v("language")]),t._v(", an injection grammar uses "),e("code",[t._v("injectTo")]),t._v(" to specify a list of target language scopes to inject the grammar into.")]),t._v(" "),e("p",[t._v("For this example, we'll create a very simple injection grammar that highlights "),e("code",[t._v("TODO")]),t._v(" as a keyword in javascript comments. To apply our injection grammar in javascript files, we use the "),e("code",[t._v("source.js")]),t._v(" target language scope in "),e("code",[t._v("injectTo")]),t._v(":")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contributes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"grammars"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"path"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./syntaxes/injection.json"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"todo-comment.injection"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"injectTo"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.js"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("The grammar itself is a standard TextMate grammar except for the top level "),e("code",[t._v("injectionSelector")]),t._v(" entry. The "),e("code",[t._v("injectionSelector")]),t._v(" is a scope selector that specifies which scopes the injected grammar should be applied in. For our example, we want to highlight the word "),e("code",[t._v("TODO")]),t._v(" in all "),e("code",[t._v("//")]),t._v(" comments. Using the "),e("a",{attrs:{href:"#scope-inspector"}},[t._v("scope inspector")]),t._v(", we find that JavaScript's double slash comments have the scope "),e("code",[t._v("comment.line.double-slash")]),t._v(", so our injection selector is "),e("code",[t._v("L:comment.line.double-slash")]),t._v(":")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"todo-comment.injection"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"injectionSelector"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"L:comment.line.double-slash"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"patterns"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"include"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"#todo-keyword"')]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"repository"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"todo-keyword"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"match"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"TODO"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"name"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"keyword.todo"')]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("p",[t._v("The "),e("code",[t._v("L:")]),t._v(" in the injection selector means that the injection is added to the left of existing grammar rules. This basically means that our injected grammar's rules will be applied before any existing grammar rules.")]),t._v(" "),e("h3",{attrs:{id:"embedded-languages-2"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#embedded-languages-2","aria-hidden":"true"}},[t._v("#")]),t._v(" Embedded languages")]),t._v(" "),e("p",[t._v("Injection grammars can also contribute embedded languages to their parent grammar. Just like with a normal grammar, an injection grammars can use "),e("code",[t._v("embeddedLanguages")]),t._v(" to map scopes from the embedded language to a top level language scope.")]),t._v(" "),e("p",[t._v("An extension that highlights sql queries in javascript strings for example may use "),e("code",[t._v("embeddedLanguages")]),t._v(" to make sure all token inside the string marked "),e("code",[t._v("meta.embedded.inline.sql")]),t._v(" are treated as sql for basic language features such as bracket matching and snippet selection.")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contributes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"grammars"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"path"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./syntaxes/injection.json"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sql-string.injection"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"injectTo"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.js"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"embeddedLanguages"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"meta.embedded.inline.sql"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sql"')]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])]),e("h3",{attrs:{id:"token-types-and-embedded-languages"}},[e("a",{staticClass:"header-anchor",attrs:{href:"#token-types-and-embedded-languages","aria-hidden":"true"}},[t._v("#")]),t._v(" Token types and embedded languages")]),t._v(" "),e("p",[t._v("There is one additional complication for injection languages embedded languages: by default, VS Code treats all tokens within a string as string contents and all tokens with a comment as token content. Since features such as bracket matching and auto closing pairs are disabled inside of strings and comments, if the embedded language appears inside a string or comment, these features will also be disabled in the embedded language.")]),t._v(" "),e("p",[t._v("To override this behavior, you can use a "),e("code",[t._v("meta.embedded.*")]),t._v(" scope to reset VS Code's marking of tokens as string or comment content. It is a good idea to always wrap embedded language in a "),e("code",[t._v("meta.embedded.*")]),t._v(" scope to make sure VS Code treats the embedded language properly.")]),t._v(" "),e("p",[t._v("If you can't add a "),e("code",[t._v("meta.embedded.*")]),t._v(" scope to your grammar, you can alternatively use "),e("code",[t._v("tokenTypes")]),t._v(" in the grammar's contribution point to map specific scopes to content mode. The "),e("code",[t._v("tokenTypes")]),t._v(" section below ensures that any content in the "),e("code",[t._v("my.sql.template.string")]),t._v(" scope is treated as source code:")]),t._v(" "),e("div",{staticClass:"language-json extra-class"},[e("pre",{pre:!0,attrs:{class:"language-json"}},[e("code",[e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"contributes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"grammars"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"path"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"./syntaxes/injection.json"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"scopeName"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sql-string.injection"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"injectTo"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"source.js"')]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"embeddedLanguages"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"my.sql.template.string"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"sql"')]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"tokenTypes"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("{")]),t._v("\n          "),e("span",{pre:!0,attrs:{class:"token property"}},[t._v('"my.sql.template.string"')]),e("span",{pre:!0,attrs:{class:"token operator"}},[t._v(":")]),t._v(" "),e("span",{pre:!0,attrs:{class:"token string"}},[t._v('"other"')]),t._v("\n        "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n      "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n    "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),t._v("\n  "),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n"),e("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("}")]),t._v("\n")])])])])}),[],!1,null,null,null);a.default=n.exports}}]);